#  DBT Code Challenge - Pipeline Spots de TV y Radio

Este proyecto es parte de un challenge tÃ©cnico para un puesto como **Data Engineer**, y tiene como objetivo crear un pipeline con DBT que unifique spots de televisiÃ³n y radio provenientes de distintos mercados de LatinoamÃ©rica.

## DescripciÃ³n del Proyecto

Se trabajo con datasets de dos paÃ­ses: **Brasil** y **MÃ©xico**. Cada paÃ­s tiene su propio formato y caracterÃ­sticas Ãºnicas, por lo que el reto consiste en:

- Estandarizar columnas clave (fecha, marca, canal, medio, duraciÃ³n, hora).
- Homologar marcas y canales (por ejemplo, todos los ESPN como "ESPN").
- Crear segmentaciÃ³n horaria (`Day`, `Primetime`, `Greytime`).
- Imputar costos faltantes con promedios por segmento.
- Unificar ambas fuentes en una tabla de hechos (`fct_spots`).


## ğŸ“ Estructura del Repositorio

dbt_spots/
â”œâ”€â”€ datasets/ # Carpeta de datasets de entrada (simulan la nube)
â”‚ â”œâ”€â”€ mercado_brasil_20240831.csv
â”‚ â””â”€â”€ mercado_mexico_20240831.csv
â”œâ”€â”€ seeds/ # Seeds utilizados por DBT
â”‚ â”œâ”€â”€ mercado_brasil_20240831.csv
â”‚ â””â”€â”€ mercado_mexico_20240831.csv
â”œâ”€â”€ models/
â”‚ â”œâ”€â”€ staging/
â”‚ â”‚ â”œâ”€â”€ stg_spots_brasil.sql
â”‚ â”‚ â””â”€â”€ stg_spots_mexico.sql
â”‚ â””â”€â”€ marts/
â”‚ â””â”€â”€ spots/
â”‚ â””â”€â”€ fct_spots.sql
â”œâ”€â”€ dbt_project.yml
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

---
## Base de datos utilizada para este proyecto

### sqlite3

## SimulaciÃ³n de almacenamiento en la nube

Debido a las restricciones del entorno, **los datasets fueron alojados localmente en la carpeta `datasets/` y referenciados como seeds por DBT**. Esta simulaciÃ³n permite emular un entorno de cloud storage sin depender de un proveedor externo.

---
## Requerimientos
```
dbt-core==1.10.6
dbt-sqlite==1.10.0
```

## InstalaciÃ³n y EjecuciÃ³n

### 1. Instalar dependencias
```
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

### 2. Ejecutar DBT
```
dbt seed         # Cargar datasets como tablas base
dbt run          # Ejecutar pipeline completo
dbt docs generate && dbt docs serve  # (Opcional) Explorar la documentaciÃ³n
```
## Transformaciones Principales
Limpieza y trim de marcas y canales

- NormalizaciÃ³n de "ESPN"
- ConversiÃ³n de formatos de fecha y hora
- CategorizaciÃ³n de horarios en segmentos publicitarios
- ImputaciÃ³n de valores nulos usando promedios por segmento (sÃ³lo Brasil)
- UniÃ³n final en una tabla de negocio con campos clave

## "Resumen del Proceso y DesafÃ­os" 

  El proyecto consistiÃ³ en construir un modelo de datos unificado a partir de fuentes heterogÃ©neas de Brasil y MÃ©xico. El principal reto fue la falta de estandarizaciÃ³n en marcas, canales y formatos de hora, ademÃ¡s de valores nulos en costos en el dataset de Brasil. Para resolverlo, se aplicaron limpiezas de texto, normalizaciÃ³n de entidades (como "ESPN"), y se imputaron costos faltantes mediante promedios por segmento. TambiÃ©n se diseÃ±Ã³ una lÃ³gica robusta para clasificar los horarios en franjas (Day, Primetime, Greytime). El resultado es una tabla de hechos consistente y lista para anÃ¡lisis de inversiÃ³n publicitaria por paÃ­s, medio y franja horaria. 

